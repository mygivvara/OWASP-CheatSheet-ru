# Node.js Шпаргалка для Docker

В приведенной ниже шпаргалке приведены практические рекомендации по созданию оптимизированного и [безопасного Node.js Docker](https://snyk.io/blog/10-best-practices-to-containerize-nodejs-web-applications-with-docker/). Вы найдете ее полезной независимо от того, какое Node.js приложение вы планируете создать. Эта статья будет полезна вам, если:

- ваша цель - создать интерфейсное приложение с использованием серверного рендеринга (SSR) Node.js возможности Reactor.
- вам нужен совет о том, как правильно создать Node.js Образ Docker для ваших микросервисов, работающих под управлением Fastify, NestJS или других платформ приложений.

## 1) Используйте явные и детерминированные теги базовых изображений Docker

Может показаться очевидным выбором создать свой образ на основе образа Docker `node`, но что вы на самом деле получаете при создании образа? На изображения в Docker всегда ссылаются теги, и если вы не указываете тег, по умолчанию используется тег `:latest`.

Таким образом, фактически, указав следующее в своем файле Dockerfile, вы всегда создаете последнюю версию образа Docker, созданную **рабочей группой Node.js Docker**:

### FROM node

Недостатки построения на основе образа `node` по умолчанию заключаются в следующем:

1. Сборки образов Docker несовместимы. Точно так же, как мы используем `lockfiles` для получения детерминированного поведения `npm install` при каждой установке пакетов npm, мы также хотели бы получать детерминированные сборки образов docker. Если мы создадим образ из node, что фактически означает тег `node:latest`, то при каждой сборке будет создаваться новый образ Docker для `node`. Мы не хотим вводить такого рода недетерминированное поведение.
2. Образ node Docker основан на полноценной операционной системе, полной библиотек и инструментов, которые могут вам понадобиться, а могут и не понадобиться для запуска вашего Node.js веб-приложение. У этого есть два недостатка. Во-первых, чем больше изображение, тем больше объем загружаемого файла, что, помимо увеличения требований к хранилищу, увеличивает время загрузки и повторного создания образа. Во-вторых, это означает, что вы потенциально вносите в изображение уязвимости в системе безопасности, которые могут существовать во всех этих библиотеках и инструментах.

На самом деле, образ `node` Docker довольно большой и содержит сотни уязвимостей в системе безопасности различных типов и степени тяжести. Если вы используете его, то по умолчанию вашей отправной точкой будет базовый уровень из 642 уязвимостей в системе безопасности и сотни мегабайт данных об изображениях, которые загружаются при каждом извлечении и сборке.

Вот рекомендации по созданию более качественных образов Docker::

1. Используйте образы Docker небольшого размера — это уменьшит нагрузку на программное обеспечение в образе Docker, уменьшит потенциальные уязвимости и уменьшит размер, что ускорит процесс создания образа
2. Используйте Docker image digest, который представляет собой статический SHA256-хэш изображения. Это гарантирует, что вы получаете детерминированные сборки Docker image из базового изображения.

Исходя из этого, давайте убедимся, что мы используем версию с долгосрочной поддержкой (LTS) Node.js и минимальный тип изображения `alpine`, чтобы оно имело наименьший размер и занимало меньше места в программном обеспечении:

### FROM node:lts-alpine

Тем не менее, эта директива base image по-прежнему будет использовать новые сборки этого тега. Мы можем найти хэш `SHA256` для него в [Docker Hub для этого Node.js тэга](https://hub.docker.com/layers/node/library/node/its-alpine/images/sha256-51e341881c2b77e52778921c685e711a186a71b8c6f62ff2edfc6b6950225a2f?context=explore), или выполнив следующую команду, как только мы извлекли это изображение локально, и найдите поле `Digest` в выходных данных:

    $ docker pull node:lts-alpine
    lts-alpine: Pulling from library/node
    0a6724ff3fcd: Already exists
    9383f33fa9f3: Already exists
    b6ae88d676fe: Already exists
    565e01e00588: Already exists
    Digest: sha256:b2da3316acdc2bec442190a1fe10dc094e7ba4121d029cb32075ff59bb27390a
    Status: Downloaded newer image for node:lts-alpine
    docker.io/library/node:lts-alpine

Другой способ найти хэш `SHA256` - это выполнить следующую команду:

    $ docker images --digests
    REPOSITORY                     TAG              DIGEST                                                                    IMAGE ID       CREATED             SIZE
    node                           lts-alpine       sha256:b2da3316acdc2bec442190a1fe10dc094e7ba4121d029cb32075ff59bb27390a   51d926a5599d   2 weeks ago         116MB

Теперь мы можем обновить файл Dockerfile для этого Node.js Образа Docker следующим образом:

    FROM node@sha256:b2da3316acdc2bec442190a1fe10dc094e7ba4121d029cb32075ff59bb27390a
    WORKDIR /usr/src/app
    COPY . /usr/src/app
    RUN npm install
    CMD "npm" "start"

Однако приведенный выше файл Dockerfile определяет только Node.js Название изображения в Docker без тега image, что создает неопределенность в отношении того, для какого именно тега используется изображение — оно нечитаемо, его сложно поддерживать и оно не создает благоприятных условий для разработчиков.

Давайте исправим это, обновив Dockerfile, указав полный базовый тег изображения для версии Node.js, соответствующей хэшу `SHA256`:

    FROM node:lts-alpine@sha256:b2da3316acdc2bec442190a1fe10dc094e7ba4121d029cb32075ff59bb27390a
    WORKDIR /usr/src/app
    COPY . /usr/src/app
    RUN npm install
    CMD "npm" "start"

## 2) Устанавливайте только производственные зависимости в образе Node.js Docker

Следующая директива Dockerfile устанавливает все зависимости в контейнере, включая `devDependencies`, которые не нужны для работы функционального приложения. Это создает ненужную угрозу безопасности из-за пакетов, используемых в качестве зависимостей для разработки, а также без необходимости увеличивает размер образа.

**`RUN npm install`**

Применяйте детерминированные сборки с помощью `npm ci`. Это предотвращает неожиданные изменения в потоке непрерывной интеграции (CI), поскольку он останавливается при любых отклонениях от файла блокировки.

В случае создания образа Docker для производственной среды мы хотим убедиться, что устанавливаем производственные зависимости только детерминированным образом, и это подводит нас к следующей рекомендации по наилучшей практике установки зависимостей npm в образе контейнера:

**`RUN npm ci --omit=dev`**

Обновленное содержимое файла Dockerfile на этом этапе выглядит следующим образом:

    FROM node:lts-alpine@sha256:b2da3316acdc2bec442190a1fe10dc094e7ba4121d029cb32075ff59bb27390a
    WORKDIR /usr/src/app
    COPY . /usr/src/app
    RUN npm ci --omit=dev
    CMD "npm" "start"

## 3) Оптимизировать Node.js оснастку для производства

Когда вы создаете свой Node.js Образ Docker для рабочей среды, вы хотите убедиться, что все платформы и библиотеки используют оптимальные настройки для повышения производительности и безопасности.

Это позволяет нам добавить следующую директиву Dockerfile:

**`ENV NODE_ENV production`**

На первый взгляд, это выглядит излишним, поскольку мы уже указали только производственные зависимости на этапе `npm install` — так зачем это нужно?

Разработчики в основном связывают настройку переменной среды `NODE_ENV=production` с установкой зависимостей, связанных с производством, однако эта настройка также имеет другие эффекты, о которых мы должны знать.

Некоторые фреймворки и библиотеки могут включать оптимизированную конфигурацию, подходящую для работы, только в том случае, если переменной среды `NODE_ENV` присвоено значение `production`. Оставляя в стороне наше мнение о том, является ли это хорошей или плохой практикой для фреймворков, важно знать следующее.

В качестве примера, [Express documentation](https://expressjs.com/en/advanced/best-practice-performance.html#set-node_env-to-production) описывает важность настройки этой переменной среды для обеспечения оптимизации производительности и безопасности:

![Express documentation screenshot](https://lh3.googleusercontent.com/idNDKUUyML-rRpnNYmOo4eNBimq-u343401spkAdKWWKjNt0c_xux2Aw1W2r64qWGEcvxfQRkosPcO339g5DzQk0snm1nr6MupSPNB_zAtGgLsr3lp1L-tia4KgHwvOXMW1jT0J-)

Влияние переменной `NODE_ENV` на производительность может быть очень значительным.

Многие другие библиотеки, на которые вы полагаетесь, также могут ожидать, что эта переменная будет установлена, поэтому мы должны установить ее в нашем Dockerfile.

Обновленный файл Dockerfile теперь должен выглядеть следующим образом с параметром переменной окружения `NODE_ENV`, заданным в:

    FROM node:lts-alpine@sha256:b2da3316acdc2bec442190a1fe10dc094e7ba4121d029cb32075ff59bb27390a
    ENV NODE_ENV production
    WORKDIR /usr/src/app
    COPY . /usr/src/app
    RUN npm ci --omit=dev
    CMD "npm" "start"

## 4) Не запускайте контейнеры от имени root

Принцип минимальных привилегий-давний контроль безопасности с первых дней существования Unix и мы всегда должны следовать этому, когда мы теряем наши контейнерные веб-приложений Node.js.

Оценка угрозы довольно проста - если злоумышленник сможет скомпрометировать веб—приложение таким образом, что это позволит использовать [внедрение команды](https://owasp.org/www-community/attacks/Command_Injection) или [обход пути к каталогу] (https://owasp.org/www-community/attacks/Path_Traversal), то они будут запущены пользователем, которому принадлежит процесс приложения. Если этот процесс принадлежит root, то он может выполнять практически все действия внутри контейнера, включая [попытку выхода из контейнера или повышения привилегий](https://owasp.org/www-project-web-security-testing-guide/latest/4-Web_Application_Security_Testing/05-Authorization_Testing/03-Testing_for_Privilege_Escalation). Зачем нам рисковать? Вы правы, мы этого не делаем.

Повторяйте за мной: **«Друзья не позволяют друзьям запускать контейнеры от имени root!»**.

Официальный образ Docker `node`, а также его варианты, такие как `alpine`, включают пользователя с наименьшими привилегиями с тем же именем: `node`. Однако недостаточно просто запустить процесс как `node`. Например, приведенные ниже действия могут оказаться неидеальными для нормальной работы приложения:

    USER node
    CMD "npm" "start"

Причина этого в том, что директива `USER` Dockerfile гарантирует, что процесс принадлежит только пользователю `node`. Как насчет всех файлов, которые мы скопировали ранее с помощью команды `COPY`? Они принадлежат root. По умолчанию Docker работает именно так.

Ниже приведен полный и правильный способ удаления привилегий, в котором также показаны наши современные методы работы с файлами Dockerfile на данный момент:

    FROM node:lts-alpine@sha256:b2da3316acdc2bec442190a1fe10dc094e7ba4121d029cb32075ff59bb27390a
    ENV NODE_ENV production
    WORKDIR /usr/src/app
    COPY --chown=node:node . /usr/src/app
    RUN npm ci --omit=dev
    USER node
    CMD "npm" "start"

## 5) Правильно обрабатывать события для безопасного завершения работы Node.js Веб-приложение Docker

Одна из самых распространенных ошибок, которую я вижу в блогах и статьях о контейнеризации Node.js приложения, запущенные в контейнерах Docker, - это способ, которым они запускают процесс. Все перечисленное ниже и их варианты являются плохими моделями поведения, которых вам следует избегать:

- `CMD “npm” “start”`
- `CMD [“yarn”, “start”]`
- `CMD “node” “server.js”`
- `CMD “start-app.sh”`

Давайте разберемся! Я расскажу вам о различиях между ними и о том, почему их следует избегать.

Следующие соображения являются ключевыми для понимания контекста правильного запуска и завершения работы Node.js Приложений Docker:

1. Механизм оркестрации, такой как Docker Swarm, Kubernetes или даже просто сам Docker engine, нуждается в способе отправки сигналов процессу в контейнере. В основном, это сигналы для завершения работы приложения, такие как `SIGTERM` и `SIGKILL`.
2. Процесс может запускаться косвенно, и если это произойдет, то не всегда гарантируется, что он получит эти сигналы.
3. Ядро Linux обрабатывает процессы, которые выполняются с идентификатором процесса 1 (PID), иначе, чем любой другой идентификатор процесса.

Вооружившись этими знаниями, давайте начнем изучать способы вызова процесса для контейнера, начав с примера из Dockerfile, который мы создаем:

**`CMD "npm" "start"`**

Здесь есть два нюанса. Во-первых, мы косвенно запускаем приложение node, напрямую вызывая клиент npm. Кто сказал, что интерфейс CLI npm перенаправляет все события в среду выполнения node? На самом деле это не так, и мы можем легко это проверить.

Убедитесь, что в вашем приложении Node.js вы настроили обработчик событий для сигнала `SIGHUP`, который регистрируется на консоли каждый раз, когда вы отправляете событие. Простой пример кода должен выглядеть следующим образом:

    function handle(signal) {
       console.log(`*^!@4=> Received event: ${signal}`)
    }
    process.on('SIGHUP', handle)

Затем запустите контейнер и, как только он будет запущен, отправьте ему специальный сигнал `SIGHUP`, используя CLI `docker` и специальный флаг командной строки `--signal`:

**`$ docker kill --signal=SIGHUP elastic_archimedes`**

Ничего не произошло, верно? Это потому, что клиент npm не передает никаких сигналов процессу node, который он породил.

Другое предостережение связано с различными способами, которыми вы можете указать директиву `CMD` в файле Dockerfile. Есть два способа, и они не совпадают:

1. нотация shell form, в которой контейнер запускает интерпретатор оболочки, который завершает процесс. В таких случаях оболочка может неправильно передавать сигналы вашему процессу.
2. нотация exec form, которая непосредственно запускает процесс, не помещая его в оболочку. Он задается с помощью обозначения массива JSON, например: `CMD [“npm”, “start”]`. Любые сигналы, отправляемые в контейнер, напрямую передаются процессу.

Основываясь на этих знаниях, мы хотим улучшить нашу директиву по выполнению процесса Dockerfile следующим образом:

**`CMD ["node", "server.js"]`**

Теперь мы вызываем процесс node напрямую, гарантируя, что он получит все отправленные ему сигналы, без использования интерпретатора оболочки.

Однако это приводит к еще одному подводному камню.

Когда процессы запускаются с идентификатором PID 1, они фактически берут на себя часть обязанностей системы инициализации, которая обычно отвечает за инициализацию операционной системы и процессов. Ядро обрабатывает PID 1 иначе, чем другие идентификаторы процессов. Это специальное решение ядра означает, что обработка сигнала `SIGTERM` запущенному процессу не приведет к резервному поведению по умолчанию, заключающемуся в завершении процесса, если процесс еще не установил для него обработчик.

Цитирую [рекомендацию рабочей группы Node.js Docker](https://github.com/nodejs/docker-node/blob/master/docs/BestPractices.md#handling-kernel-signals) по этому поводу:  «Node.js не был разработан для запуска в качестве PID 1, что приводит к неожиданному поведению при запуске внутри Docker. Например, процесс Node.js, запущенный как PID 1, не будет реагировать на SIGINT (CTRL-C) и подобные сигналы».

Тогда для этого нужно использовать инструмент, который будет действовать как процесс инициализации, поскольку он вызывается с PID 1, а затем запускает наше Node.js приложение как другой процесс, обеспечивая при этом, чтобы все сигналы передавались этому Node.js процессу. Если это возможно, мы хотели бы использовать как можно меньше инструментов для этого, чтобы избежать риска добавления уязвимостей в наш образ контейнера.

Одним из таких инструментов является [dumb-init](https://engineeringblog.yelp.com/2016/01/dumb-init-an-init-for-docker.html), который статически связан и занимает мало места. Вот как мы его настроим:

    RUN apk add dumb-init
    CMD ["dumb-init", "node", "server.js"]

Это подводит нас к следующему обновленному файлу Dockerfile. Вы заметите, что мы поместили установку пакета `dumb-init` сразу после объявления изображения, чтобы мы могли воспользоваться преимуществами кэширования слоев в Docker:

    FROM node:lts-alpine@sha256:b2da3316acdc2bec442190a1fe10dc094e7ba4121d029cb32075ff59bb27390a
    RUN apk add dumb-init
    ENV NODE_ENV production
    WORKDIR /usr/src/app
    COPY --chown=node:node . .
    RUN npm ci --omit=dev
    USER node
    CMD ["dumb-init", "node", "server.js"]

Полезно знать: команды `docker kill` и `docker stop` посылают сигналы контейнерному процессу только с PID 1. Если вы используете сценарий оболочки, который запускает ваше приложение Node.js, обратите внимание, что экземпляр оболочки, такой как, например, "/bin/sh", не пересылает сигналы дочерним процессам, что означает, что ваше приложение никогда не получит `SIGTERM`.

## 6) Услужливое завершение работы ваших веб-приложений Node.js

Если мы уже обсуждаем сигналы процесса, которые завершают работу приложений, давайте убедимся, что мы завершаем их должным образом и корректно, не нарушая работу пользователей.

Когда Node.js приложение получает сигнал прерывания, также известный как `SIGINT` или `CTRL+C`, это приводит к внезапному завершению процесса, если, конечно, не были настроены какие-либо обработчики событий для обработки этого по-другому. Это означает, что подключенные к веб-приложению клиенты будут немедленно отключены. А теперь представьте себе сотни Node.js веб-контейнеры, управляемые Kubernetes, расширяются и закрываются по мере необходимости для масштабирования или устранения ошибок. Не самый лучший пользовательский опыт.

Вы можете легко смоделировать эту проблему. Вот пример стандартного веб-приложения Fastify, в котором конечная точка реагирует с задержкой в 60 секунд:

    fastify.get('/delayed', async (request, reply) => {
     const SECONDS_DELAY = 60000
     await new Promise(resolve => {
         setTimeout(() => resolve(), SECONDS_DELAY)
     })
     return { hello: 'delayed world' }
    })
     
    const start = async () => {
     try {
       await fastify.listen(PORT, HOST)
       console.log(`*^!@4=> Process id: ${process.pid}`)
     } catch (err) {
       fastify.log.error(err)
       process.exit(1)
     }
    }
     
    start()

Запустите это приложение и, как только оно запустится, отправьте простой HTTP-запрос на эту конечную точку:

`$ time curl https://localhost:3000/delayed`

Нажмите `CTRL+C` в запущенном окне консоли Node.js, и вы увидите, что запрос curl внезапно завершился. Это имитирует тот же опыт, который ваши пользователи получили бы при демонтаже контейнеров.

Чтобы обеспечить лучший опыт, мы можем сделать следующее:

1. Установить обработчик событий для различных сигналов завершения, таких как `SIGINT` и `SIGTERM`.
2. Обработчик ожидает операций очистки, таких как подключения к базе данных, текущие HTTP-запросы и другие.
3. Затем обработчик завершает процесс Node.js.

В частности, с помощью Fastify мы можем вызвать обработчик [fastify.close()](https://www.fastify.io/docs/latest/Server/), который возвращает обещание, которое мы будем ожидать, и Fastify также позаботится о том, чтобы отвечать на каждое новое соединение с кодом состояния HTTP 503, сигнализируя о том, что приложение недоступно.

Давайте добавим наш обработчик событий:

    async function closeGracefully(signal) {
       console.log(`*^!@4=> Received signal to terminate: ${signal}`)
     
       await fastify.close()
       // await db.close() if we have a db connection in this app
       // await other things we should cleanup nicely
       process.exit()
    }
    process.on('SIGINT', closeGracefully)
    process.on('SIGTERM', closeGracefully)

По общему признанию, это скорее относится к общим веб-приложениям, чем к Dockerfile, но еще более важно в организованных средах.

## 7) Поиск и устранение уязвимостей безопасности в докер-образе Node.js

Смотрите [Шпаргалку по безопасности Docker - Использование статического анализа tools](https://cheatsheetseries.owasp.org/cheatsheets/Docker_Security_Cheat_Sheet.html#rule-9-use-static-analysis-tools)

## 8) Используйте многоступенчатые сборки

Многоступенчатая сборка - отличный способ перейти от простого, но потенциально ошибочного файла Dockerfile к отдельным этапам создания образа Docker, чтобы избежать утечки конфиденциальной информации. Кроме того, мы также можем использовать более крупный базовый образ Docker для установки наших зависимостей, при необходимости скомпилировать любые собственные пакеты npm, а затем скопировать все эти артефакты в небольшой производственный базовый образ, как в нашем примере с alpine.

### Предотвращение утечки конфиденциальной информации

Приведенный здесь пример использования для предотвращения утечки конфиденциальной информации встречается чаще, чем вы думаете.

Если вы создаете образы Docker для работы, велика вероятность, что вы также поддерживаете частные пакеты npm. Если это так, то вам, вероятно, нужно было найти какой-то способ сделать этот секретный `NPM_TOKEN` доступным для установки npm.

Вот пример того, о чем я говорю:

    FROM node:lts-alpine@sha256:b2da3316acdc2bec442190a1fe10dc094e7ba4121d029cb32075ff59bb27390a
    RUN apk add dumb-init
    ENV NODE_ENV production
    ENV NPM_TOKEN 1234
    WORKDIR /usr/src/app
    COPY --chown=node:node . .
    #RUN npm ci --omit=dev
    RUN echo "//registry.npmjs.org/:_authToken=$NPM_TOKEN" > .npmrc && \
       npm ci --omit=dev
    USER node
    CMD ["dumb-init", "node", "server.js"]

Однако при этом файл `.npmrc` с секретным токеном npm остается внутри образа Docker. Вы можете попытаться улучшить его, удалив его впоследствии, вот так:

    RUN echo "//registry.npmjs.org/:_authToken=$NPM_TOKEN" > .npmrc && \
       npm ci --omit=dev
    RUN rm -rf .npmrc

Однако теперь файл `.npmrc` доступен на другом уровне образа Docker. Если этот образ Docker является общедоступным или кто-то может каким-либо образом получить к нему доступ, то ваш токен скомпрометирован. Лучшим улучшением было бы следующее:

    RUN echo "//registry.npmjs.org/:_authToken=$NPM_TOKEN" > .npmrc && \
       npm ci --omit=dev; \
       rm -rf .npmrc

Проблема сейчас в том, что сам файл Dockerfile должен рассматриваться как секретный ресурс, поскольку внутри него содержится секретный токен npm.

К счастью, Docker поддерживает способ передачи аргументов в процесс сборки:

    ARG NPM_TOKEN
    RUN echo "//registry.npmjs.org/:_authToken=$NPM_TOKEN" > .npmrc && \
       npm ci --omit=dev; \
       rm -rf .npmrc

И затем мы собираем его следующим образом:

**`$ docker build . -t nodejs-tutorial --build-arg NPM_TOKEN=1234`**

Я знаю, вы думали, что на данный момент мы все закончили, но, извините, что разочаровываю 🙂

Вот как обстоит дело с безопасностью — иногда очевидные вещи становятся еще одной ловушкой.

В чем проблема, как вы думаете? Аргументы сборки, переданные таким образом в Docker, сохраняются в журнале истории. Давайте посмотрим своими глазами. Запустите эту команду:

**`$ docker history nodejs-tutorial`**

который выводит следующее:

    IMAGE          CREATED              CREATED BY                                      SIZE      COMMENT
    b4c2c78acaba   About a minute ago   CMD ["dumb-init" "node" "server.js"]            0B        buildkit.dockerfile.v0
    <missing>      About a minute ago   USER node                                       0B        buildkit.dockerfile.v0
    <missing>      About a minute ago   RUN |1 NPM_TOKEN=1234 /bin/sh -c echo "//reg…   5.71MB    buildkit.dockerfile.v0
    <missing>      About a minute ago   ARG NPM_TOKEN                                   0B        buildkit.dockerfile.v0
    <missing>      About a minute ago   COPY . . # buildkit                             15.3kB    buildkit.dockerfile.v0
    <missing>      About a minute ago   WORKDIR /usr/src/app                            0B        buildkit.dockerfile.v0
    <missing>      About a minute ago   ENV NODE_ENV=production                         0B        buildkit.dockerfile.v0
    <missing>      About a minute ago   RUN /bin/sh -c apk add dumb-init # buildkit     1.65MB    buildkit.dockerfile.v0

Вы заметили там секретный токен npm? Вот что я имею в виду.

Есть отличный способ управлять секретами для образа контейнера, но сейчас самое время представить многоступенчатую сборку в качестве решения этой проблемы, а также показать, как мы можем создавать минимальные образы.

### Внедрение многоступенчатых сборок для Docker-образов Node.js

Как этот принцип в разработке программного обеспечения разделения, мы будем применять те же идеи, для того, чтобы строить свою Node.js Docker изображений. У нас будет один образ, который мы будем использовать для создания всего, что нам нужно для запуска приложения Node.js, что в мире Node.js означает установку пакетов npm и, при необходимости, компиляцию собственных модулей npm. Это будет нашим первым этапом.

Вторым образом Docker, представляющим второй этап сборки Docker, будет рабочий образ Docker. Этот второй и последний этап - это образ, который мы фактически оптимизируем и публикуем в реестре, если он у нас есть. Этот первый образ, который мы будем называть образом `build`, будет удален и останется незавершенным на хосте Docker, который его создал, до тех пор, пока он не будет очищен.

Вот обновление нашего файла Dockerfile, которое отражает наш прогресс на данный момент, но разделено на два этапа:

    # --------------> The build image
    FROM node:latest AS build
    ARG NPM_TOKEN
    WORKDIR /usr/src/app
    COPY package*.json /usr/src/app/
    RUN echo "//registry.npmjs.org/:_authToken=$NPM_TOKEN" > .npmrc && \
       npm ci --omit=dev && \
       rm -f .npmrc
     
    # --------------> The production image
    FROM node:lts-alpine@sha256:b2da3316acdc2bec442190a1fe10dc094e7ba4121d029cb32075ff59bb27390a
    RUN apk add dumb-init
    ENV NODE_ENV production
    USER node
    WORKDIR /usr/src/app
    COPY --chown=node:node --from=build /usr/src/app/node_modules /usr/src/app/node_modules
    COPY --chown=node:node . /usr/src/app
    CMD ["dumb-init", "node", "server.js"]

Как вы можете видеть, я выбрал изображение большего размера для этапа `build`, потому что мне могут понадобиться инструменты, такие как `gcc` (коллекция компиляторов GNU), для компиляции собственных пакетов npm или для других нужд.

На втором этапе существует специальное обозначение для директивы `COPY`, которая копирует папку `node_modules/` из образа средства настройки сборки в этот новый производственный базовый образ.

Кроме того, теперь вы видите, что `NPM_TOKEN` передается в качестве аргумента сборки промежуточному образу Docker `build`? Он больше не отображается в выходных данных команды `docker history nodejs-tutorial`, потому что его нет в нашем рабочем образе docker.

## 9) Не допускайте попадания ненужных файлов в Docker-образы Node.js

У вас есть файл `.gitignore`, чтобы не засорять репозиторий git ненужными файлами, а также потенциально конфиденциальными файлами, верно? То же самое относится и к изображениям Docker.

В Docker есть параметр `.dockerignore`, который гарантирует, что он не будет отправлять демону Docker любые совпадения с шаблоном glob внутри него. Вот список файлов, который даст вам представление о том, что вы могли бы поместить в свой образ Docker, чего мы в идеале хотели бы избежать:

    .dockerignore
    node_modules
    npm-debug.log
    Dockerfile
    .git
    .gitignore

Как вы можете видеть, `node_modules/` на самом деле очень важно пропустить, потому что если бы мы не проигнорировали его, то упрощенная версия Dockerfile, с которой мы начали, привела бы к тому, что локальная папка `node_modules/` была бы скопирована в контейнер как есть.

    FROM node@sha256:b2da3316acdc2bec442190a1fe10dc094e7ba4121d029cb32075ff59bb27390a
    WORKDIR /usr/src/app
    COPY . /usr/src/app
    RUN npm install
    CMD "npm" "start"

На самом деле, еще важнее иметь файл `.dockerignore`, когда вы практикуете многоэтапные сборки Docker. Чтобы освежить в памяти, как выглядит сборка Docker на 2-м этапе:

    # --------------> The production image
    FROM node:lts-alpine
    RUN apk add dumb-init
    ENV NODE_ENV production
    USER node
    WORKDIR /usr/src/app
    COPY --chown=node:node --from=build /usr/src/app/node_modules /usr/src/app/node_modules
    COPY --chown=node:node . /usr/src/app
    CMD ["dumb-init", "node", "server.js"]

Важность наличия `.dockerignore` заключается в том, что когда мы выполняем `COPY . /usr/src/app` со 2-го этапа Dockerfile, мы также копируем любой локальный node\_modules/ в образ Docker. Это большой запрет, так как мы, возможно, копируем измененный исходный код внутри `node_modules/`.

Кроме того, поскольку мы используем подстановочный знак `COPY .`, мы также можем скопировать в образ Docker конфиденциальные файлы, содержащие учетные данные или локальную конфигурацию.

Вывод из этого для файла `.dockerignore` таков::

- Пропустить потенциально измененные копии `node_modules/` в образе Docker.
- Защищает вас от раскрытия секретов, таких как учетные данные в содержимом файлов `.env` или `aws.json`, которые попадают в Node.js Изображение Docker.
- Это помогает ускорить сборку в Docker, поскольку игнорирует файлы, которые в противном случае привели бы к аннулированию кэша. Например, если бы был изменен файл журнала или файл конфигурации локальной среды, все это привело бы к недействительности кэша изображений Docker на этом уровне копирования через локальный каталог.

## 10) Встраивание секретов в образ сборки Docker

Следует отметить, что файл `.dockerignore` - это подход «все или ничего», и его нельзя включать или выключать на каждом этапе сборки в многоэтапной сборке Docker.

Почему это важно? В идеале, мы хотели бы использовать файл `.npmrc` на этапе сборки, поскольку он может нам понадобиться, поскольку он содержит секретный токен npm для доступа к закрытым пакетам npm. Возможно, для извлечения пакетов также требуется определенная конфигурация прокси-сервера или реестра.

Это означает, что имеет смысл иметь файл `.npmrc` доступным на этапе `build`, однако на втором этапе он нам вообще не нужен для создания рабочего образа, и мы не хотим его там, поскольку он может содержать конфиденциальную информацию, например, секретный токен npm.

Один из способов устранить эту проблему с `.dockerignore` - смонтировать локальную файловую систему, которая будет доступна на этапе сборки, но есть способ получше.

Docker поддерживает относительно новую функцию, называемую Docker secrets, и она идеально подходит для того случая, когда нам нужен `.npmrc`. Вот как это работает:

- Когда мы запустим команду `docker build`, мы укажем аргументы командной строки, которые определяют новый секретный идентификатор и ссылаются на файл в качестве источника секрета.
- В Dockerfile мы добавим флаги к директиве `RUN` для установки рабочего npm, который монтирует файл, на который ссылается секретный идентификатор, в целевое местоположение — локальный каталог с файлом `.npmrc`, который находится там, где мы хотим, чтобы он был доступен.
- Файл `.npmrc` монтируется как секретный и никогда не копируется в образ Docker.
- Наконец, давайте не забудем добавить файл ".npmrc" к содержимому файла `.dockerignore`, чтобы он вообще не попал в образ ни для сборки, ни для рабочих образов.

Давайте посмотрим, как все это работает вместе. Сначала обновленный файл `.dockerignore`:

    .dockerignore
    node_modules
    npm-debug.log
    Dockerfile
    .git
    .gitignore
    .npmrc

Затем полный файл Dockerfile с обновленной директивой RUN для установки пакетов npm с указанием точки монтирования `.npmrc`:

    # --------------> The build image
    FROM node:latest AS build
    WORKDIR /usr/src/app
    COPY package*.json /usr/src/app/
    RUN --mount=type=secret,mode=0644,id=npmrc,target=/usr/src/app/.npmrc npm ci --omit=dev
     
    # --------------> The production image
    FROM node:lts-alpine
    RUN apk add dumb-init
    ENV NODE_ENV production
    USER node
    WORKDIR /usr/src/app
    COPY --chown=node:node --from=build /usr/src/app/node_modules /usr/src/app/node_modules
    COPY --chown=node:node . /usr/src/app
    CMD ["dumb-init", "node", "server.js"]

И, наконец, команда, которая создает Node.js Образ Docker:

    docker build . -t nodejs-tutorial --secret id=npmrc,src=.npmrc

**Примечание:** Секреты - это новая функция в Docker, и если вы используете более старую версию, вам может потребоваться включить ее в Buildkit следующим образом:

    DOCKER_BUILDKIT=1 docker build . -t nodejs-tutorial --build-arg NPM_TOKEN=1234 --secret id=npmrc,src=.npmrc
